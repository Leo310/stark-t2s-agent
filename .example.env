# Example environment variables for STaRK-Prime T2S Agent
# Copy this to ".env" and fill in secrets/overrides.

# Local cache directory (optional). Default: ~/.cache/stark-t2s-agent
# STARK_CACHE_DIR=/path/to/cache

# LLM provider: "openai" or "openrouter"
LLM_PROVIDER=openai

# OpenAI configuration
# Set your OpenAI API key
OPENAI_API_KEY=
OPENAI_MODEL=gpt-5-mini

# OpenRouter configuration (if using openrouter provider)
OPENROUTER_API_KEY=
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_MODEL=openai/gpt-4o-mini

# PostgreSQL (used by local docker-compose services)
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=stark_prime
POSTGRES_USER=stark
POSTGRES_PASSWORD=stark_password

# Fuseki SPARQL endpoint
FUSEKI_HOST=localhost
FUSEKI_PORT=3031
FUSEKI_DATASET=prime
FUSEKI_ADMIN_PASSWORD=admin

# Qdrant vector DB
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=stark_entities_full

# Langfuse observability
# Set to "true" or "false"
LANGFUSE_ENABLED=true
LANGFUSE_SECRET_KEY=
LANGFUSE_PUBLIC_KEY=
LANGFUSE_BASE_URL=https://cloud.langfuse.com

# MLflow observability (Databricks-hosted)
# Note: MLflow and Langfuse are mutually exclusive; only enable one.
MLFLOW_ENABLED=false
DATABRICKS_TOKEN=
DATABRICKS_HOST=
MLFLOW_TRACKING_URI=databricks
MLFLOW_REGISTRY_URI=databricks-uc
MLFLOW_EXPERIMENT_ID=
